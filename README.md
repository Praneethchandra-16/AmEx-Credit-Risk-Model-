       Credit Risk Modeling â€“ AMEX Case Study

This project presents an end-to-end machine learning solution to predict credit default risk, using a real-world industrial-scale dataset provided by American Express as part of their Kaggle competition: AMEX Default Prediction.
________________________________________
ğŸ§­ Introduction
In the evolving landscape of consumer lending, accurately identifying creditworthy individuals is crucial for minimizing risk and maximizing customer satisfaction. This project leverages machine learning techniques to enhance credit default prediction, enabling financial institutions like American Express to offer credit products to the right customers at the right time.
By modeling customer behavior using time-series transactional data and anonymized profile information, we can build a more robust, explainable, and high-performing model that improves upon traditional risk models. This ensures better approval decisions, reduces potential losses, and ultimately enhances the customer experience.
ğŸ”— Data Source: Kaggle Competition â€“ AMEX Default Prediction
________________________________________
ğŸ§  Key Contributions
â€¢	âœ… Handled a large-scale dataset (5.5M+ rows) with efficient chunking
â€¢	âœ… Performed missing value treatment, categorical encoding, and temporal aggregation over 12-month periods
â€¢	âœ… Engineered features like mean, min, max, and last for numeric time-series variables
â€¢	âœ… Applied one-hot encoding to categorical variables, generating 45+ new features
â€¢	âœ… Built and compared two models: XGBoost and a Neural Network, using extensive grid search
â€¢	âœ… Selected the final model based on AUC performance and variance stability across training and test splits
â€¢	âœ… Used SHAP values for model explainability and to understand feature contributions to risk prediction
________________________________________
ğŸ“ Project Structure
ğŸ“¦ Credit_Risk_Modeling
 â”£ ğŸ“Š AMEX_Credit_Risk_Analysis.ipynb
 â”£ ğŸ“ˆ Credit Risk Model.pptx
 â”£ ğŸ§  credit_risk_modeling.py
 â”£ ğŸ“„ final_data_for_project.csv
 â”— ğŸ“˜ README.md
________________________________________
ğŸ¯ Objective
To build an accurate and explainable credit risk model using machine learning that can challenge the existing production model used by American Express. The project implements two modeling strategies and selects the best based on AUC performance:
âœ… XGBoost
ğŸ§ª Neural Network
________________________________________
ğŸ“‚ Data Overview
â€¢	Total Customers: 91,783
â€¢	Time Span: 13 months of historical data
â€¢	Categories of Features:
o	D_ - Delinquency
o	B_ - Balance
o	S_ - Spend
o	P_ - Payment
o	R_ - Risk
________________________________________
âš™ï¸ Feature Engineering
â€¢	ğŸ“… Aggregated temporal features: mean, min, max, last over 12 months
â€¢	ğŸ·ï¸ One-hot encoded 11 categorical columns â†’ 45 dummy variables
â€¢	ğŸ§¼ Missing values handled based on type:
o	Binary â†’ 0
o	Categorical â†’ Mode
o	Numeric â†’ Mean
________________________________________
ğŸ§ª Model Training
1ï¸âƒ£ XGBoost
â€¢	Grid search on:
o	Trees: 50, 100, 300
o	Learning rates: 0.01, 0.1
o	Row subsample: 50%, 80%
o	Feature subsample: 50%, 100%
o	Class weight: 1, 5, 10
â€¢	âœ… 72 models trained
â€¢	ğŸ“ˆ Best AUC performance on Test 2
â€¢	ğŸ’¡ SHAP analysis used for model interpretability
2ï¸âƒ£ Neural Network
â€¢	Outliers capped to 99th percentile
â€¢	Normalized using StandardScaler
â€¢	Grid search on:
o	Hidden layers: 2, 4
o	Neurons: 4, 6
o	Activation: ReLU, Tanh
o	Dropout: 50%, 100%
o	Batch size: 100, 10000
â€¢	Trained 32 models
â€¢	âŒ Did not outperform XGBoost
________________________________________
ğŸ“Š SHAP Value Insights (XGBoost)
Feature	Impact
P_2_last	Negative
B_1_last	Negative
D_39_max	Positive
S_3_mean	Positive
SHAP values helped explain how each feature contributes to a prediction.
________________________________________
ğŸ† Final Model Selection
â€¢	âœ… XGBoost outperformed NN across all sets (Train, Test1, Test2)
â€¢	Highest AUC with lowest variance
â€¢	Chosen as the final model for production-ready implementation
________________________________________
ğŸš€ Future Enhancements
â€¢	Streamlit dashboard for real-time scoring
â€¢	AutoML model comparison
â€¢	Model monitoring for drift detection
________________________________________
ğŸ“ˆ Results Summary
Model	AUC (Test2)	Remarks
XGBoost	âœ… High	Best performer overall
Neural Net	Moderate	Underperformed
________________________________________
ğŸ›  Tech Stack
â€¢	Python, Pandas, NumPy
â€¢	Matplotlib, Seaborn
â€¢	LightGBM, XGBoost, Scikit-Learn
â€¢	SHAP, GridSearchCV
â€¢	PowerPoint for stakeholder communication
________________________________________
ğŸ“£ Let's Connect
For questions, improvements, or collaboration, feel free to reach out or fork the repo!



